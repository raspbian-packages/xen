x86: don't leak ST(n)/XMMn values to domains first using them

FNINIT doesn't alter these registers, and hence using it is
insufficient to initialize a guest's initial state.

This is XSA-165.

Signed-off-by: Jan Beulich <jbeulich@suse.com>
Reviewed-by: Andrew Cooper <andrew.cooper3@citrix.com>
[Backported to Xen 4.1.x]
Signed-off-by: Stefan Bader <stefan.bader@canonical.com>

--- a/xen/arch/x86/domain.c
+++ b/xen/arch/x86/domain.c
@@ -751,6 +751,37 @@ int arch_set_info_guest(
 
     v->fpu_initialised = !!(flags & VGCF_I387_VALID);
 
+    if ( !v->fpu_initialised )
+    {
+        if ( v->arch.xsave_area )
+        {
+          memset(&v->arch.xsave_area->xsave_hdr, 0,
+                 sizeof(v->arch.xsave_area->xsave_hdr));
+          v->arch.xsave_area->fpu_sse.mxcsr = MXCSR_DEFAULT;
+        }
+        else
+        {
+            if ( cpu_has_fxsr )
+            {
+                typeof(v->arch.xsave_area->fpu_sse) *fpu_sse =
+                    (void *)v->arch.guest_context.fpu_ctxt.x;
+
+                memset(fpu_sse, 0, sizeof(*fpu_sse));
+                fpu_sse->fcw = FCW_DEFAULT;
+                fpu_sse->mxcsr = MXCSR_DEFAULT;
+            }
+            else
+            {
+                struct ix87_state *fpu =
+                    (void *)v->arch.guest_context.fpu_ctxt.x;
+
+                memset(fpu, 0, sizeof(*fpu));
+                fpu->env.fcw = FCW_DEFAULT;
+                fpu->env.ftw = 0xffff;
+            }
+        }
+    }
+
     v->arch.flags &= ~TF_kernel_mode;
     if ( (flags & VGCF_in_kernel) || is_hvm_vcpu(v)/*???*/ )
         v->arch.flags |= TF_kernel_mode;
--- a/xen/arch/x86/i387.c
+++ b/xen/arch/x86/i387.c
@@ -80,13 +80,6 @@ static void xrstor(struct vcpu *v)
                    : "ecx" );
 }
 
-static void load_mxcsr(unsigned long val)
-{
-    val &= 0xffbf;
-    asm volatile ( "ldmxcsr %0" : : "m" (val) );
-}
-
-static void init_fpu(void);
 static void restore_fpu(struct vcpu *v);
 
 void setup_fpu(struct vcpu *v)
@@ -99,6 +92,13 @@ void setup_fpu(struct vcpu *v)
     if ( v->fpu_dirtied )
         return;
 
+    if ( !v->fpu_initialised && v->arch.xsave_area )
+    {
+        memset(&v->arch.xsave_area->xsave_hdr, 0,
+               sizeof(v->arch.xsave_area->xsave_hdr));
+        v->arch.xsave_area->fpu_sse.mxcsr = MXCSR_DEFAULT;
+    }
+
     if ( xsave_enabled(v) )
     {
         /*
@@ -109,26 +109,37 @@ void setup_fpu(struct vcpu *v)
         xrstor(v);
         set_xcr0(v->arch.xcr0);
     }
-    else if ( v->fpu_initialised )
-    {
-        restore_fpu(v);
-    }
     else
     {
-        init_fpu();
+        if ( !v->fpu_initialised )
+        {
+            if ( cpu_has_fxsr )
+            {
+                typeof(v->arch.xsave_area->fpu_sse) *fpu_sse =
+                    (void *)v->arch.guest_context.fpu_ctxt.x;
+
+                memset(fpu_sse, 0, sizeof(*fpu_sse));
+                fpu_sse->fcw = FCW_DEFAULT;
+                fpu_sse->mxcsr = MXCSR_DEFAULT;
+            }
+            else
+            {
+                struct ix87_state *fpu =
+                    (void *)v->arch.guest_context.fpu_ctxt.x;
+
+                memset(fpu, 0, sizeof(*fpu));
+                fpu->env.fcw = FCW_DEFAULT;
+                fpu->env.ftw = 0xffff;
+            }
+        }
+
+        restore_fpu(v);
     }
 
     v->fpu_initialised = 1;
     v->fpu_dirtied = 1;
 }
 
-static void init_fpu(void)
-{
-    asm volatile ( "fninit" );
-    if ( cpu_has_xmm )
-        load_mxcsr(0x1f80);
-}
-
 void save_init_fpu(struct vcpu *v)
 {
     unsigned long cr0;
--- a/xen/arch/x86/domctl.c
+++ b/xen/arch/x86/domctl.c
@@ -1537,7 +1537,7 @@ long arch_do_domctl(
             }
             offset += sizeof(v->arch.xcr0_accum);
             if ( copy_to_guest_offset(domctl->u.vcpuextstate.buffer,
-                                      offset, v->arch.xsave_area,
+                                      offset, (void *)v->arch.xsave_area,
                                       xsave_cntxt_size) )
             {
                 ret = -EFAULT;
--- a/xen/include/asm-x86/domain.h
+++ b/xen/include/asm-x86/domain.h
@@ -423,7 +423,7 @@ struct arch_vcpu
      * dirtied FPU/SSE) is scheduled out we XSAVE the states here; 2) in
      * #NM handler, we XRSTOR the states we XSAVE-ed;
      */
-    void *xsave_area;
+    struct xsave_struct *xsave_area;
     uint64_t xcr0;
     /* Accumulated eXtended features mask for using XSAVE/XRESTORE by Xen
      * itself, as we can never know whether guest OS depends on content
--- a/xen/include/asm-x86/i387.h
+++ b/xen/include/asm-x86/i387.h
@@ -38,6 +38,24 @@ bool_t xsave_enabled(const struct vcpu *
 #define FCW_DEFAULT               0x037f
 #define MXCSR_DEFAULT             0x1f80
 
+struct ix87_state {
+    struct ix87_env {
+        uint16_t fcw, _res0;
+        uint16_t fsw, _res1;
+        uint16_t ftw, _res2;
+        uint32_t fip;
+        uint16_t fcs;
+        uint16_t fop;
+        uint32_t fdp;
+        uint16_t fds, _res6;
+    } env;
+    struct ix87_reg {
+        uint64_t mantissa;
+        uint16_t exponent:15;
+        uint16_t sign:1;
+    } __attribute__((__packed__)) r[8];
+};
+
 struct xsave_struct
 {
     union {                                  /* FPU/MMX, SSE */
