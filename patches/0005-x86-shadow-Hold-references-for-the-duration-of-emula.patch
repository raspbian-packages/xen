From 0f8bc20e4e83a4ca3843e6e898caa7b22acf3aca Mon Sep 17 00:00:00 2001
From: Andrew Cooper <andrew.cooper3@citrix.com>
Date: Thu, 11 May 2017 14:47:00 +0100
Subject: [PATCH 05/16] x86/shadow: Hold references for the duration of
 emulated writes

The (misnamed) emulate_gva_to_mfn() function translates a linear address to an
mfn, but releases its page reference before returning the mfn to its caller.

sh_emulate_map_dest() uses the results of one or two translations to construct
a virtual mapping to the underlying frames, completes an emulated
write/cmpxchg, then unmaps the virtual mappings.

The page references need holding until the mappings are unmapped, or the
frames can change ownership before the writes occurs.

This is XSA-219

Reported-by: Andrew Cooper <andrew.cooper3@citrix.com>
Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
Reviewed-by: Jan Beulich <jbeulich@suse.com>
Reviewed-by: Tim Deegan <tim@xen.org>

Adapted to xen 4.1 by Peter Dreuw <peter.dreuw@credativ.de>
Signed-off-by: Peter Dreuw <peter.dreuw@credativ.de>
---
 xen/arch/x86/mm/shadow/multi.c | 53 +++++++++++++++++++++++++++++-------------
 1 file changed, 37 insertions(+), 16 deletions(-)

diff --git a/xen/arch/x86/mm/shadow/multi.c b/xen/arch/x86/mm/shadow/multi.c
index 97e35c09c..4878b46dc 100644
--- a/xen/arch/x86/mm/shadow/multi.c
+++ b/xen/arch/x86/mm/shadow/multi.c
@@ -4824,7 +4824,10 @@ static void sh_pagetable_dying(struct vcpu *v, paddr_t gpa)
 /**************************************************************************/
 /* Handling HVM guest writes to pagetables  */
 
-/* Translate a VA to an MFN, injecting a page-fault if we fail */
+/*
+ * Translate a VA to an MFN, injecting a page-fault if we fail.  If the
+ * mapping succeeds, a reference will be held on the underlying page.
+ */
 #define BAD_GVA_TO_GFN (~0UL)
 #define BAD_GFN_TO_MFN (~1UL)
 #define READONLY_GFN   (~2UL)
@@ -4866,8 +4869,11 @@ static mfn_t emulate_gva_to_mfn(struct vcpu *v,
     return mfn;
 }
 
-/* Check that the user is allowed to perform this write. 
- * Returns a mapped pointer to write to, or NULL for error. */
+/*
+ * Check that the user is allowed to perform this write.  If a mapping is
+ * returned, page references will be held on sh_ctxt->mfn1 and
+ * sh_ctxt->mfn2 iff !INVALID_MFN.
+ */
 #define MAPPING_UNHANDLEABLE ((void *)(unsigned long)X86EMUL_UNHANDLEABLE)
 #define MAPPING_EXCEPTION    ((void *)(unsigned long)X86EMUL_EXCEPTION)
 #define MAPPING_SILENT_FAIL  ((void *)(unsigned long)X86EMUL_OKAY)
@@ -4880,13 +4886,6 @@ static void *emulate_map_dest(struct vcpu *v,
     unsigned long offset;
     void *map = NULL;
 
-    sh_ctxt->mfn1 = emulate_gva_to_mfn(v, vaddr, sh_ctxt);
-    if ( !mfn_valid(sh_ctxt->mfn1) ) 
-        return ((mfn_x(sh_ctxt->mfn1) == BAD_GVA_TO_GFN) ?
-                MAPPING_EXCEPTION :
-                (mfn_x(sh_ctxt->mfn1) == READONLY_GFN) ?
-                MAPPING_SILENT_FAIL : MAPPING_UNHANDLEABLE);
-
 #ifndef NDEBUG
     /* We don't emulate user-mode writes to page tables */
     if ( hvm_get_seg_reg(x86_seg_ss, sh_ctxt)->attr.fields.dpl == 3 )
@@ -4896,6 +4895,17 @@ static void *emulate_map_dest(struct vcpu *v,
         return MAPPING_UNHANDLEABLE;
     }
 #endif
+
+    sh_ctxt->mfn1 = emulate_gva_to_mfn(v, vaddr, sh_ctxt);
+    if ( !mfn_valid(sh_ctxt->mfn1) )
+    {
+        switch ( mfn_x(sh_ctxt->mfn1) )
+        {
+        case BAD_GVA_TO_GFN: return MAPPING_EXCEPTION;
+        case READONLY_GFN:   return MAPPING_SILENT_FAIL;
+        default:             return MAPPING_UNHANDLEABLE;
+        }
+    }
                 
     /* Unaligned writes mean probably this isn't a pagetable */
     if ( vaddr & (bytes - 1) )
@@ -4912,16 +4922,24 @@ static void *emulate_map_dest(struct vcpu *v,
         /* Cross-page emulated writes are only supported for HVM guests; 
          * PV guests ought to know better */
         if ( !is_hvm_vcpu(v) )
+        {
+            put_page(mfn_to_page(sh_ctxt->mfn1));
             return MAPPING_UNHANDLEABLE;
+        }
 
         /* This write crosses a page boundary.  Translate the second page */
         sh_ctxt->mfn2 = emulate_gva_to_mfn(v, (vaddr + bytes - 1) & PAGE_MASK,
                                            sh_ctxt);
-        if ( !mfn_valid(sh_ctxt->mfn2) ) 
-            return ((mfn_x(sh_ctxt->mfn2) == BAD_GVA_TO_GFN) ?
-                    MAPPING_EXCEPTION :
-                    (mfn_x(sh_ctxt->mfn2) == READONLY_GFN) ?
-                    MAPPING_SILENT_FAIL : MAPPING_UNHANDLEABLE);
+        if ( !mfn_valid(sh_ctxt->mfn2) )
+        {
+            put_page(mfn_to_page(sh_ctxt->mfn1));
+            switch ( mfn_x(sh_ctxt->mfn2) )
+            {
+            case BAD_GVA_TO_GFN: return MAPPING_EXCEPTION;
+            case READONLY_GFN:   return MAPPING_SILENT_FAIL;
+            default:             return MAPPING_UNHANDLEABLE;
+            }
+        }
 
         /* Cross-page writes mean probably not a pagetable */
         sh_remove_shadows(v, sh_ctxt->mfn2, 0, 0 /* Slow, can fail */ );
@@ -5011,11 +5029,14 @@ static void emulate_unmap_dest(struct vcpu *v,
     }
 
     paging_mark_dirty(v->domain, mfn_x(sh_ctxt->mfn1));
-
+    put_page(mfn_to_page(sh_ctxt->mfn1));
+    
     if ( unlikely(mfn_valid(sh_ctxt->mfn2)) )
     {
         unsigned long offset;
         paging_mark_dirty(v->domain, mfn_x(sh_ctxt->mfn2));
+        put_page(mfn_to_page(sh_ctxt->mfn2));
+        
         /* Undo the hacky two-frame contiguous map. */
         ASSERT(((unsigned long) addr & PAGE_MASK) == LDT_VIRT_START(v));
         offset = l1_linear_offset((unsigned long) addr);
-- 
2.14.1

